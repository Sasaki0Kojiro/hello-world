{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrAFsTKC4Ab1FhNRZU+BZG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sasaki0Kojiro/hello-world/blob/main/pytorch6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diEEsw-bJLO-"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ1Z6slzJrRz"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor ,Lambda\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = ToTensor() \n",
        ")\n",
        "train_dataloader = DataLoader(training_data,batch_size=64)\n",
        "test_dataloader = DataLoader(test_data,batch_size=64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork,self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQK1P3AFPaYK"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpZuFAJXQS6Z"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbiZAaqVRdrh"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDAaxWIiR0AR"
      },
      "source": [
        "def train_loop(dataloader,model,loss_fn,optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch,(X,y) in enumerate(dataloader):\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred,y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss,current = loss.item(),batch *len(X)\n",
        "      print(f\"loss:{loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "  \n",
        "def test_loop(dataloader,model,loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  test_loss,correct = 0,0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X,y in dataloader:\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred,y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  \n",
        "  test_loss /= size\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%,Avg loss: {test_loss:>8f}\\n\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gClxetNmZOJx",
        "outputId": "a418e019-cd6e-422e-c842-fc35d2ef4f53"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n------------------------------------\")\n",
        "  train_loop(train_dataloader,model,loss_fn,optimizer)\n",
        "  test_loop(test_dataloader,model,loss_fn)\n",
        "print(\"Done!\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "------------------------------------\n",
            "loss:2.261191 [    0/60000]\n",
            "loss:2.267394 [ 6400/60000]\n",
            "loss:2.240764 [12800/60000]\n",
            "loss:2.245485 [19200/60000]\n",
            "loss:2.226507 [25600/60000]\n",
            "loss:2.169438 [32000/60000]\n",
            "loss:2.207363 [38400/60000]\n",
            "loss:2.168247 [44800/60000]\n",
            "loss:2.200818 [51200/60000]\n",
            "loss:2.112710 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 31.8%,Avg loss: 0.033934\n",
            "\n",
            "Epoch 2\n",
            "------------------------------------\n",
            "loss:2.190429 [    0/60000]\n",
            "loss:2.199202 [ 6400/60000]\n",
            "loss:2.156704 [12800/60000]\n",
            "loss:2.178811 [19200/60000]\n",
            "loss:2.098926 [25600/60000]\n",
            "loss:2.020057 [32000/60000]\n",
            "loss:2.081606 [38400/60000]\n",
            "loss:2.013475 [44800/60000]\n",
            "loss:2.089371 [51200/60000]\n",
            "loss:1.943852 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 36.3%,Avg loss: 0.031989\n",
            "\n",
            "Epoch 3\n",
            "------------------------------------\n",
            "loss:2.072297 [    0/60000]\n",
            "loss:2.086064 [ 6400/60000]\n",
            "loss:2.046959 [12800/60000]\n",
            "loss:2.095143 [19200/60000]\n",
            "loss:1.938977 [25600/60000]\n",
            "loss:1.850362 [32000/60000]\n",
            "loss:1.935114 [38400/60000]\n",
            "loss:1.857366 [44800/60000]\n",
            "loss:1.979917 [51200/60000]\n",
            "loss:1.777678 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%,Avg loss: 0.030212\n",
            "\n",
            "Epoch 4\n",
            "------------------------------------\n",
            "loss:1.960872 [    0/60000]\n",
            "loss:1.986569 [ 6400/60000]\n",
            "loss:1.960560 [12800/60000]\n",
            "loss:2.020471 [19200/60000]\n",
            "loss:1.802543 [25600/60000]\n",
            "loss:1.721651 [32000/60000]\n",
            "loss:1.804799 [38400/60000]\n",
            "loss:1.737810 [44800/60000]\n",
            "loss:1.861559 [51200/60000]\n",
            "loss:1.643475 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 40.4%,Avg loss: 0.028543\n",
            "\n",
            "Epoch 5\n",
            "------------------------------------\n",
            "loss:1.842810 [    0/60000]\n",
            "loss:1.886087 [ 6400/60000]\n",
            "loss:1.868873 [12800/60000]\n",
            "loss:1.950237 [19200/60000]\n",
            "loss:1.666550 [25600/60000]\n",
            "loss:1.618379 [32000/60000]\n",
            "loss:1.699820 [38400/60000]\n",
            "loss:1.647905 [44800/60000]\n",
            "loss:1.757567 [51200/60000]\n",
            "loss:1.549032 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 41.0%,Avg loss: 0.027205\n",
            "\n",
            "Epoch 6\n",
            "------------------------------------\n",
            "loss:1.746864 [    0/60000]\n",
            "loss:1.803300 [ 6400/60000]\n",
            "loss:1.794443 [12800/60000]\n",
            "loss:1.898521 [19200/60000]\n",
            "loss:1.563914 [25600/60000]\n",
            "loss:1.543285 [32000/60000]\n",
            "loss:1.625838 [38400/60000]\n",
            "loss:1.585267 [44800/60000]\n",
            "loss:1.681579 [51200/60000]\n",
            "loss:1.488392 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 41.5%,Avg loss: 0.026202\n",
            "\n",
            "Epoch 7\n",
            "------------------------------------\n",
            "loss:1.676735 [    0/60000]\n",
            "loss:1.740052 [ 6400/60000]\n",
            "loss:1.734560 [12800/60000]\n",
            "loss:1.858488 [19200/60000]\n",
            "loss:1.493507 [25600/60000]\n",
            "loss:1.487937 [32000/60000]\n",
            "loss:1.574551 [38400/60000]\n",
            "loss:1.539623 [44800/60000]\n",
            "loss:1.627275 [51200/60000]\n",
            "loss:1.447766 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 42.2%,Avg loss: 0.025453\n",
            "\n",
            "Epoch 8\n",
            "------------------------------------\n",
            "loss:1.627123 [    0/60000]\n",
            "loss:1.692075 [ 6400/60000]\n",
            "loss:1.686503 [12800/60000]\n",
            "loss:1.829025 [19200/60000]\n",
            "loss:1.445593 [25600/60000]\n",
            "loss:1.447658 [32000/60000]\n",
            "loss:1.539019 [38400/60000]\n",
            "loss:1.504895 [44800/60000]\n",
            "loss:1.589062 [51200/60000]\n",
            "loss:1.419063 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 42.8%,Avg loss: 0.024898\n",
            "\n",
            "Epoch 9\n",
            "------------------------------------\n",
            "loss:1.590292 [    0/60000]\n",
            "loss:1.654935 [ 6400/60000]\n",
            "loss:1.647965 [12800/60000]\n",
            "loss:1.806942 [19200/60000]\n",
            "loss:1.411705 [25600/60000]\n",
            "loss:1.416368 [32000/60000]\n",
            "loss:1.512046 [38400/60000]\n",
            "loss:1.478940 [44800/60000]\n",
            "loss:1.558791 [51200/60000]\n",
            "loss:1.396760 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 43.6%,Avg loss: 0.024461\n",
            "\n",
            "Epoch 10\n",
            "------------------------------------\n",
            "loss:1.559966 [    0/60000]\n",
            "loss:1.625172 [ 6400/60000]\n",
            "loss:1.615707 [12800/60000]\n",
            "loss:1.787117 [19200/60000]\n",
            "loss:1.385221 [25600/60000]\n",
            "loss:1.390380 [32000/60000]\n",
            "loss:1.489705 [38400/60000]\n",
            "loss:1.456308 [44800/60000]\n",
            "loss:1.533251 [51200/60000]\n",
            "loss:1.378875 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 44.4%,Avg loss: 0.024100\n",
            "\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOpuKQg4awOv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}